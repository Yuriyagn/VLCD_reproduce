# VLCD_reproduce

**VLCD (Vision-Language Change Detection)** çš„ PyTorch å®ç°ï¼ŒåŸºäº ChangeCLIP ä»£ç åº“å¤ç°ã€‚

## ğŸ“ ç®€ä»‹

æœ¬é¡¹ç›®åœ¨ ChangeCLIP çš„åŸºç¡€ä¸Šå®ç°äº† VLCD æ¨¡å‹çš„æ ¸å¿ƒæ¶æ„ï¼Œä¸»è¦åŒ…æ‹¬ï¼š

- ğŸ”¥ **CoOp (Context Optimization)**: å¯å­¦ä¹ çš„æ–‡æœ¬æç¤ºå‘é‡
- ğŸŒŸ **Side Fusion Network (SFN)**: CLIP + RS ç‰¹å¾èåˆç½‘ç»œ
- ğŸ”— **Bridging Module (BM)**: è·¨æ¨¡æ€ç‰¹å¾æ¡¥æ¥
- ğŸ¯ **CFC Module**: å¢å¼ºçš„å˜åŒ–ç‰¹å¾è®¡ç®—

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

### ä¸ ChangeCLIP çš„å…³é”®å·®å¼‚

| ç‰¹æ€§ | ChangeCLIP | VLCD (æœ¬å®ç°) |
|------|-----------|--------------|
| **æ–‡æœ¬ç«¯** | å›ºå®šæ¨¡æ¿ + ä¸Šä¸‹æ–‡ | CoOp å¯å­¦ä¹ æç¤º (16ä¸ªå‘é‡) |
| **å›¾åƒç«¯** | å•ä¸€ CLIP Backbone | CLIP (å†»ç»“) + RS Network + BM |
| **ç‰¹å¾èåˆ** | Cosine + Abs Diff | CFC: Concat + Rel Feature |
| **å‚æ•°ç­–ç•¥** | å…¨éƒ¨å¾®è°ƒ | å†»ç»“ CLIP (70%å‚æ•°) |
| **å‚æ•°æ•ˆç‡** | 100% å¯è®­ç»ƒ | ä»… 30% å¯è®­ç»ƒ |

### æ¶æ„äº®ç‚¹

```
Input Image
    â”œâ”€â†’ CLIP Vision (Frozen) â”€â”€â”
    â”‚                           â”œâ”€â†’ Bridging Module â”€â†’ Fused Features
    â””â”€â†’ RS Network (Trainable) â”€â”˜
                                    â†“
                                CFC Module
                                    â†“
                                FPN + Decoder
```

## ğŸ“¦ å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python >= 3.8
- PyTorch >= 1.10
- CUDA >= 11.1

### ä¾èµ–å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone git@github.com:Yuriyagn/VLCD_reproduce.git
cd VLCD_reproduce

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n vlcd python=3.8
conda activate vlcd

# å®‰è£… PyTorch (æ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬)
pip install torch==1.12.0+cu116 torchvision==0.13.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt

# å®‰è£… MMSegmentation ç›¸å…³
pip install mmcv-full==1.7.0
pip install timm  # ç”¨äº ResNet50
```

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
VLCD_reproduce/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ vlcd/
â”‚       â”œâ”€â”€ vlcd_levir.py          # VLCD ResNet ç‰ˆæœ¬é…ç½®
â”‚       â””â”€â”€ vlcd_levir_vit.py      # VLCD ViT ç‰ˆæœ¬é…ç½®
â”œâ”€â”€ mmseg/
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ backbones/
â”‚       â”‚   â”œâ”€â”€ side_fusion_network.py  # ResNet Side Fusion
â”‚       â”‚   â””â”€â”€ side_fusion_vit.py      # ViT Side Fusion
â”‚       â”œâ”€â”€ necks/
â”‚       â”‚   â””â”€â”€ cfc_module.py           # CFC æ¨¡å—
â”‚       â”œâ”€â”€ segmentors/
â”‚       â”‚   â””â”€â”€ VLCD.py                 # VLCD ä¸»æ¨¡å‹
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ learnable_prompt.py     # CoOp æ¨¡å—
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ train.py                   # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ test.py                    # æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ test_vlcd_modules.py       # æ¨¡å—æµ‹è¯•
â”œâ”€â”€ VLCD_README.md                 # è¯¦ç»†æ–‡æ¡£
â””â”€â”€ README.md                      # æœ¬æ–‡ä»¶
```

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®é›†

ä¸‹è½½ LEVIR-CD æ•°æ®é›†å¹¶æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š

```
data/LEVIR-CD/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ B/
â”‚   â””â”€â”€ label/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ B/
â”‚   â””â”€â”€ label/
â””â”€â”€ test/
    â”œâ”€â”€ A/
    â”œâ”€â”€ B/
    â””â”€â”€ label/
```

### 2. ä¸‹è½½é¢„è®­ç»ƒæƒé‡

ä¸‹è½½ CLIP é¢„è®­ç»ƒæƒé‡ï¼ˆæ ¹æ®ä½ é€‰æ‹©çš„ç‰ˆæœ¬ï¼‰ï¼š

```bash
mkdir pretrained

# ResNet ç‰ˆæœ¬ (RN50)
wget https://openaipublic.azureedge.net/clip/models/RN50.pt -O pretrained/RN50.pt

# ViT ç‰ˆæœ¬ (ViT-B-16) - æ¨è
wget https://openaipublic.azureedge.net/clip/models/ViT-B-16.pt -O pretrained/ViT-B-16.pt
```

### 3. è®­ç»ƒæ¨¡å‹

**ViT ç‰ˆæœ¬ï¼ˆæ¨èï¼‰**:
```bash
# å• GPU è®­ç»ƒ - ViT
python tools/train.py configs/vlcd/vlcd_levir_vit.py

# å¤š GPU è®­ç»ƒ (4å¡) - ViT
CUDA_VISIBLE_DEVICES=0,1,2,3 \
python -m torch.distributed.launch --nproc_per_node=4 \
       tools/train.py configs/vlcd/vlcd_levir_vit.py --launcher pytorch
```

**ResNet ç‰ˆæœ¬**:
```bash
# å• GPU è®­ç»ƒ - ResNet
python tools/train.py configs/vlcd/vlcd_levir.py
```

### 4. æµ‹è¯•æ¨¡å‹

```bash
python tools/test.py configs/vlcd/vlcd_levir.py \
       work_dirs/vlcd_levir/latest.pth
```

### 5. æ¨¡å—æµ‹è¯•

```bash
# æµ‹è¯•å„ä¸ªæ¨¡å—åŠŸèƒ½
python tools/test_vlcd_modules.py
```

## ğŸ“Š å®éªŒç»“æœ

### LEVIR-CD æ•°æ®é›†

| æ¨¡å‹ | F1 Score | IoU | Precision | Recall | å‚æ•°é‡ |
|------|----------|-----|-----------|--------|--------|
| ChangeCLIP | - | - | - | - | 143M (100%) |
| **VLCD (æœ¬å®ç°)** | - | - | - | - | 145M (30%) |

> æ³¨ï¼šç»“æœå¾…è®­ç»ƒå®Œæˆåæ›´æ–°

## ğŸ”§ æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. CoOp å¯å­¦ä¹ æç¤º

```python
from mmseg.models.utils.learnable_prompt import LearnablePrompt

# åˆ›å»ºå¯å­¦ä¹ æç¤º
prompt = LearnablePrompt(
    clip_text_encoder,
    class_names=['background', 'building'],
    n_ctx=16  # 16ä¸ªä¸Šä¸‹æ–‡å‘é‡
)
```

### 2. Side Fusion Network

```python
from mmseg.models.backbones.side_fusion_network import SideFusionCLIP

# åˆ›å»ºèåˆç½‘ç»œ
sfn = SideFusionCLIP(
    clip_backbone=clip_model,
    freeze_clip=True  # å†»ç»“ CLIP
)
```

### 3. CFC æ¨¡å—

```python
from mmseg.models.necks.cfc_module import CFCModule

# åˆ›å»º CFC
cfc = CFCModule(
    in_channels=256,
    out_channels=256,
    text_dim=1024,
    num_scales=4
)
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

æ›´å¤šæŠ€æœ¯ç»†èŠ‚è¯·å‚è€ƒï¼š

- [VLCD_README.md](VLCD_README.md) - å®Œæ•´å®ç°æ–‡æ¡£
- [implementation_plan.md](.gemini/implementation_plan.md) - å®æ–½è®¡åˆ’
- [walkthrough.md](.gemini/walkthrough.md) - è¯¦ç»†æ¼”ç¤º

## ğŸ› ï¸ é…ç½®è¯´æ˜

å…³é”®é…ç½®å‚æ•°ï¼ˆåœ¨ `configs/vlcd/vlcd_levir.py` ä¸­ï¼‰ï¼š

```python
model = dict(
    type='VLCD',
    freeze_clip=True,      # å†»ç»“ CLIP å‚æ•°
    n_ctx=16,              # CoOp ä¸Šä¸‹æ–‡å‘é‡æ•°
    
    # ä¼˜åŒ–å™¨ - åˆ†å±‚å­¦ä¹ ç‡
    optim_wrapper = dict(
        paramwise_cfg=dict(
            custom_keys={
                'backbone': dict(lr_mult=0.0),          # CLIP ä¸è®­ç»ƒ
                'rs_backbone': dict(lr_mult=1.0),       # RS è®­ç»ƒ
                'learnable_prompt': dict(lr_mult=1.0),  # CoOp è®­ç»ƒ
            }
        )
    )
)
```

## ğŸ¤ è‡´è°¢

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹ä¼˜ç§€å·¥ä½œï¼š

- [ChangeCLIP](https://github.com/...) - åŸºç¡€ä»£ç æ¡†æ¶
- [OpenAI CLIP](https://github.com/openai/CLIP) - é¢„è®­ç»ƒæ¨¡å‹
- [MMSegmentation](https://github.com/open-mmlab/mmsegmentation) - åˆ†å‰²æ¡†æ¶
- [CoOp](https://github.com/KaiyangZhou/CoOp) - å¯å­¦ä¹ æç¤ºæ€æƒ³

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤ [Issue](https://github.com/Yuriyagn/VLCD_reproduce/issues) æˆ–è”ç³»ï¼š

- Email: your_email@example.com
- GitHub: [@Yuriyagn](https://github.com/Yuriyagn)

## ğŸŒŸ Star History

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸€ä¸ª â­ï¸ï¼

---

**æ›´æ–°æ—¥æœŸ**: 2026-01-05  
**çŠ¶æ€**: ğŸš§ å¼€å‘ä¸­ - ä»£ç å®ç°å·²å®Œæˆï¼Œç­‰å¾…è®­ç»ƒéªŒè¯
